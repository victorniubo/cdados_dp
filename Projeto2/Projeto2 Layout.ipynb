{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Giovanni dos Santos\n",
    "\n",
    "## Gustavo Tessitore\n",
    "\n",
    "## Victor Niubó\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Problema\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando: \n",
    "    \n",
    "    75% dos dados para a parte Treinamento; e\n",
    "    25% dos dados para a parte Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_excel(\"spamham2019.xlsx\") #lê o excel\n",
    "remover = [',','@','/',':',';','r$','\\n','\\(','\\)','#','\\?','-','\"','\\[','\\]']\n",
    "\n",
    "for i in remover:\n",
    "    emails.Email = emails.Email.replace(i,'',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicio = emails.to_dict('records')\n",
    "shuffle(dicio)\n",
    "df2 = pd.DataFrame.from_dict(dicio)\n",
    "df3 = df2.head(int(len(df2)*0.75))\n",
    "df4 = df2.tail(int(len(df2)*0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de ser relevante: 86 %\n",
      "Probabilidade de ser irrelevante 13 %\n"
     ]
    }
   ],
   "source": [
    "spam = df3.Class\n",
    "\n",
    "prob = spam.value_counts()\n",
    "\n",
    "prob_ham = prob[0]/len(spam) \n",
    "\n",
    "prob_spam = prob[1]/len(spam) \n",
    "\n",
    "print(\"Probabilidade de ser relevante:\",int(prob_ham * 100),'%')\n",
    "print('Probabilidade de ser irrelevante',int(prob_spam * 100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to     1152\n",
       "you    1113\n",
       "I       799\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presunto = df3[df3.Class == 'ham'] #Separa os presuntos relevantes\n",
    "relevantes = np.sum(presunto.Email).split()\n",
    "quant_em_relev =  pd.Series(relevantes)\n",
    "todos_relevantes = len(relevantes)\n",
    "quant_em_relev.value_counts().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "queijo = df3[df3.Class == 'spam'] #Separa os queijos relevantes\n",
    "irelevantes = np.sum(queijo.Email).split()\n",
    "quant_em_irelev =  pd.Series(irelevantes)\n",
    "todos_irelevantes = len(irelevantes)\n",
    "quant_em_irelev.value_counts().head(3)\n",
    "\n",
    "todas_as_palavras = irelevantes + relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gugat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def P_spam_palavra(palavra):\n",
    "    if palavra in irelevantes:\n",
    "        return ((1 + quant_em_irelev.value_counts()[palavra])/(len(todas_as_palavras) + len(irelevantes)))\n",
    "    else:\n",
    "        return 1/(len(todas_as_palavras) + len(irelevantes))\n",
    "    \n",
    "def P_palavra_spam(palavra):\n",
    "    x = (P_spam_palavra(palavra) * P_palavra(palavra)) / prob_spam\n",
    "    return x\n",
    "\n",
    "def P_palavra(palavra):\n",
    "    quant_pal = (quant_em_irelev.value_counts()[palavra] + quant_em_relev.value_counts()[palavra])\n",
    "    quant_tot = len(irelevantes)+len(relevantes)\n",
    "    return (quant_pal/quant_tot)\n",
    "\n",
    "def P_ham_palavra(palavra):\n",
    "    if palavra in relevantes:\n",
    "        return ((1 + quant_em_relev.value_counts()[palavra])/(len(todas_as_palavras) + len(relevantes)))\n",
    "    else:\n",
    "        return 1/(len(todas_as_palavras) + len(irelevantes))\n",
    "    \n",
    "def P_palavra_ham(palavra):\n",
    "    x = (P_ham_palavra(palavra) * P_palavra(palavra)) / prob_ham\n",
    "    return x\n",
    "\n",
    "def P_spam_mensagem(mensagem):\n",
    "    palavras = mensagem.split(' ')\n",
    "    prob = 0\n",
    "    contador = 0\n",
    "    for palavra in palavras:\n",
    "        if palavra in todas_as_palavras:\n",
    "            if contador == 0:\n",
    "                prob += P_spam_palavra(palavra)\n",
    "            else:\n",
    "                prob *= P_spam_palavra(palavra)\n",
    "        else:\n",
    "            pass\n",
    "    return prob\n",
    "\n",
    "def P_ham_mensagem(mensagem):\n",
    "    palavras = mensagem.split(' ')\n",
    "    prob = 0\n",
    "    contador = 0\n",
    "    for palavra in palavras:\n",
    "        if palavra in todas_as_palavras:\n",
    "            if contador == 0:\n",
    "                prob += P_ham_palavra(palavra)\n",
    "            else:\n",
    "                prob *= P_ham_palavra(palavra)\n",
    "        else:\n",
    "            pass\n",
    "    return prob\n",
    "\n",
    "def Hamlet(mensagem):\n",
    "    ham = P_ham_mensagem(mensagem)\n",
    "    spam = P_spam_mensagem(mensagem)\n",
    "    if ham > spam:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'spam'\n",
    "\n",
    "test = []\n",
    "for i in range(len(df3.Email)):\n",
    "    test.append(Hamlet(df3.Email[i]))\n",
    "\n",
    "df3['NB'] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de falsos positivos: 0.4%\n",
      "Porcentagem de positivos verdadeiros: 1.6%\n",
      "Porcentagem de falsos negativos: 11.4%\n",
      "Porcentagem de negativos verdadeiros: 86.6%\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "falso_neg = 0\n",
    "falso_pos = 0\n",
    "pos_ver = 0\n",
    "neg_ver = 0\n",
    "Spam = 0\n",
    "Ham = 0\n",
    "\n",
    "for e in range(500):\n",
    "    if df3.Class[e] == 'spam':\n",
    "        Spam += 1\n",
    "        if df3.NB[e] == 'spam':\n",
    "            pos_ver += 1\n",
    "        \n",
    "        elif df3.NB[e] != 'spam':\n",
    "            falso_neg += 1\n",
    "    \n",
    "    elif df3.Class[e] == 'ham':\n",
    "        Ham += 1\n",
    "        if df3.NB[e] == 'ham' :\n",
    "            neg_ver += 1\n",
    "        \n",
    "        elif df3.NB[e] != 'ham':\n",
    "            falso_pos += 1\n",
    "            \n",
    "total = falso_neg + falso_pos + pos_ver + neg_ver            \n",
    "\n",
    "print('Porcentagem de falsos positivos: {0}%'.format(falso_pos/ * 100))\n",
    "print('Porcentagem de positivos verdadeiros: {0}%'.format(pos_ver/ * 100))\n",
    "print('Porcentagem de falsos negativos: {0}%'.format(falso_neg/ * 100))\n",
    "print('Porcentagem de negativos verdadeiros: {0}%'.format(neg_ver/ * 100))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Qualidade do Classificador alterando a base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
