{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Giovanni dos Santos\n",
    "\n",
    "## Gustavo Tessitore\n",
    "\n",
    "## Victor Niubó\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Problema\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando: \n",
    "    \n",
    "    75% dos dados para a parte Treinamento; e\n",
    "    25% dos dados para a parte Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_excel(\"spamham2019.xlsx\") #lê o excel\n",
    "remover = [',','@','/',':',';','r$','\\n','\\(','\\)','#','\\?','-','\"','\\[','\\]']\n",
    "\n",
    "for i in remover:\n",
    "    emails.Email = emails.Email.replace(i,'',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicio = emails.to_dict('records')\n",
    "shuffle(dicio)\n",
    "df2 = pd.DataFrame.from_dict(dicio)\n",
    "df3 = df2.head(int(len(df2)*0.75))\n",
    "df4 = df2.tail(int(len(df2)*0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de ser relevante: 86 %\n",
      "Probabilidade de ser irrelevante 13 %\n"
     ]
    }
   ],
   "source": [
    "spam = df3.Class\n",
    "\n",
    "prob = spam.value_counts()\n",
    "\n",
    "prob_ham = prob[0]/len(spam) \n",
    "\n",
    "prob_spam = prob[1]/len(spam) \n",
    "\n",
    "print(\"Probabilidade de ser relevante:\",int(prob_ham * 100),'%')\n",
    "print('Probabilidade de ser irrelevante',int(prob_spam * 100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to     1132\n",
       "you    1124\n",
       "I       815\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presunto = df3[df3.Class == 'ham'] #Separa os presuntos relevantes\n",
    "relevantes = np.sum(presunto.Email).split()\n",
    "quant_em_relev =  pd.Series(relevantes)\n",
    "todos_relevantes = len(relevantes)\n",
    "quant_em_relev.value_counts().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to    450\n",
       "a     274\n",
       "or    137\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queijo = df3[df3.Class == 'spam'] #Separa os queijos relevantes\n",
    "irelevantes = np.sum(queijo.Email).split()\n",
    "quant_em_irelev =  pd.Series(irelevantes)\n",
    "todos_irelevantes = len(irelevantes)\n",
    "quant_em_irelev.value_counts().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_as_palavras = irelevantes + relevantes\n",
    "\n",
    "\n",
    "\n",
    "def P_spam_palavra(palavra):\n",
    "    if palavra in irelevantes:\n",
    "        return ((1 + quant_em_irelev.value_counts()[palavra])/(len(todas_as_palavras) + len(irelevantes)))\n",
    "    else:\n",
    "        return 1/(len(todas_as_palavras) + len(irelevantes))\n",
    "\n",
    "def P_palavra_spam(palavra):\n",
    "    x = (P_spam_palavra(palavra) * P_palavra(palavra)) / prob_spam\n",
    "    return x\n",
    "\n",
    "def P_palavra(palavra):\n",
    "    quant_pal = (quant_em_irelev.value_counts()[palavra] + quant_em_relev.value_counts()[palavra])\n",
    "    quant_tot = len(irelevantes)+len(relevantes)\n",
    "    return (quant_pal/quant_tot)\n",
    "\n",
    "def P_ham_palavra(palavra):\n",
    "    if palavra in relevantes:\n",
    "        return ((1 + quant_em_relev.value_counts()[palavra])/(len(todas_as_palavras) + len(relevantes)))\n",
    "    else:\n",
    "        return 1/(len(todas_as_palavras) + len(irelevantes))\n",
    "\n",
    "def P_palavra_ham(palavra):\n",
    "    x = (P_ham_palavra(palavra) * P_palavra(palavra)) / prob_ham\n",
    "    return x\n",
    "\n",
    "def P_spam_mensagem(mensagem):\n",
    "    palavras = mensagem.split(' ')\n",
    "    prob = 0\n",
    "    contador = 0\n",
    "    for palavra in palavras:\n",
    "        if palavra in todas_as_palavras:\n",
    "            if contador == 0:\n",
    "                prob += P_spam_palavra(palavra)\n",
    "            else:\n",
    "                prob *= P_spam_palavra(palavra)\n",
    "        else:\n",
    "            pass\n",
    "    return prob\n",
    "\n",
    "def P_ham_mensagem(mensagem):\n",
    "    palavras = mensagem.split(' ')\n",
    "    prob = 0\n",
    "    contador = 0\n",
    "    for palavra in palavras:\n",
    "        if palavra in todas_as_palavras:\n",
    "            if contador == 0:\n",
    "                prob += P_ham_palavra(palavra)\n",
    "            else:\n",
    "                prob *= P_ham_palavra(palavra)\n",
    "        else:\n",
    "            pass\n",
    "    return prob\n",
    "\n",
    "def Hamlet(mensagem):\n",
    "    ham = P_ham_mensagem(mensagem)\n",
    "    spam = P_spam_mensagem(mensagem)\n",
    "    if ham > spam:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'spam'\n",
    "#test = []\n",
    "\n",
    "#for i in df3.Email:\n",
    "#    test.append(Hamlet(i))\n",
    "#df3['NB'] = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O teste estava demorando em torno de vinte minutos para rodar, por isso seria inviável rodá-lo 10.000 vezes. \n",
    "Portanto, segue abaixo o código do final do Projeto rodado todas as vezes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "test1 = []\n",
    "for e in df4.Email:\n",
    "    test1.append(Hamlet(e))\n",
    "df4['NB'] = test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de positivos verdadeiros: 13.20%\n",
      "Porcentagem de negativos verdadeiros: 98.83%\n"
     ]
    }
   ],
   "source": [
    "falso_neg = 0\n",
    "falso_pos = 0\n",
    "pos_ver = 0\n",
    "neg_ver = 0\n",
    "Spam = 0\n",
    "Ham = 0\n",
    "\n",
    "for e in range(len(df5)):\n",
    "    if df5.Class[e] == 'spam':\n",
    "        Spam += 1\n",
    "        if df5.NB[e] == 'spam':\n",
    "            pos_ver += 1\n",
    "        \n",
    "        elif df5.NB[e] != 'spam':\n",
    "            falso_neg += 1\n",
    "    \n",
    "    elif df5.Class[e] == 'ham':\n",
    "        Ham += 1\n",
    "        if df5.NB[e] == 'ham' :\n",
    "            neg_ver += 1\n",
    "        \n",
    "        elif df5.NB[e] != 'ham':\n",
    "            falso_pos += 1\n",
    "            \n",
    "total = falso_neg + falso_pos + pos_ver + neg_ver            \n",
    "\n",
    "p1= float(falso_pos/Ham * 100)\n",
    "p2= float(pos_ver/Spam * 100)\n",
    "p3= float(falso_neg/Spam * 100)\n",
    "p4= float(neg_ver/Ham * 100)\n",
    "\n",
    "\n",
    "print('Porcentagem de positivos verdadeiros: {0:.2f}%'.format(p2))\n",
    "\n",
    "print('Porcentagem de negativos verdadeiros: {0:.2f}%'.format(p4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Qualidade do Classificador alterando a base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-369a3500ecb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHamlet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf9\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NB'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mposi_ver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3390\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3391\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4001\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4003\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "resultados = []\n",
    "\n",
    "for o in range(10):\n",
    "    dicio = emails.to_dict('records')\n",
    "    shuffle(dicio)\n",
    "    df6 = pd.DataFrame.from_dict(dicio)\n",
    "    df7 = df6.head(int(len(df2)*0.75))\n",
    "    df8 = df7.tail(int(len(df2)*0.25))\n",
    "    df9 = df8.reset_index(drop=True)\n",
    "    \n",
    "    test2 = []\n",
    "    for e in df9.Email:\n",
    "        test1.append(Hamlet(e))\n",
    "    df9['NB'] = test2\n",
    "    \n",
    "    posi_ver = 0\n",
    "    nega_ver = 0\n",
    "    Spam1 = 0\n",
    "    Ham1 = 0\n",
    "\n",
    "    for e in range(len(df9)):\n",
    "        if df9.Class[e] == 'spam':\n",
    "            Spam += 1\n",
    "            if df9.NB[e] == 'spam':\n",
    "                pos_ver += 1\n",
    "\n",
    "            elif df9.NB[e] != 'spam':\n",
    "                falso_neg += 1\n",
    "\n",
    "        elif df9.Class[e] == 'ham':\n",
    "            Ham += 1\n",
    "            if df9.NB[e] == 'ham' :\n",
    "                neg_ver += 1\n",
    "\n",
    "            elif df9.NB[e] != 'ham':\n",
    "                falso_pos += 1\n",
    "\n",
    "    total = falso_neg + falso_pos + pos_ver + neg_ver            \n",
    "\n",
    "    positivo_ver= float(pos_ver/Spam * 100)\n",
    "    negativo_ver= float(neg_ver/Ham * 100)\n",
    "    reults = [positivo_ver, negativo_ver]\n",
    "    \n",
    "    resultados.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
